{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98997257",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a8a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yeopu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yeopu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, InputLayer, Activation, Dropout, Dense, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7224cef",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2c0cd",
   "metadata": {},
   "source": [
    "#### Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36445a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(df):\n",
    "    df['headlines'] = df['headlines'].str.lower()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fa02f",
   "metadata": {},
   "source": [
    "#### Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af98b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "    data['headlines'] = data['headlines'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0615d",
   "metadata": {},
   "source": [
    "#### Punctuations Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fa53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(data):\n",
    "    data['headlines'] = data['headlines'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff0088",
   "metadata": {},
   "source": [
    "#### Transform Target Variable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d692ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    for i in data.index:\n",
    "        if data['sentiment'][i] == 1:\n",
    "            data['sentiment'][i] = 2\n",
    "        \n",
    "        elif data['sentiment'][i] == 0:\n",
    "            data['sentiment'][i] = 1\n",
    "        \n",
    "        else:\n",
    "            data['sentiment'][i] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec0233",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc08be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(X):\n",
    "    \n",
    "    X_tokens = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        tokens = nltk.word_tokenize(X[i])\n",
    "        X_tokens.append(tokens)\n",
    "        \n",
    "    return X_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88f0d3",
   "metadata": {},
   "source": [
    "## GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d8a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove():\n",
    "    \n",
    "    glove_vectors = dict()\n",
    "    file = open('glove.6B.100d.txt',  encoding='UTF-8')\n",
    "\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vectors = np.asarray(values[1:], dtype='float32')\n",
    "        glove_vectors[word] = vectors\n",
    "    file.close()\n",
    "    \n",
    "    return glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa8a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(data):\n",
    "    \n",
    "    glove_vectors = load_glove()\n",
    "    dim = glove_vectors[\"random\"].shape[0]\n",
    "    \n",
    "    X = np.zeros((len(data), 64, dim))\n",
    "    \n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range (len(data[i])):\n",
    "            try:\n",
    "                vector = glove_vectors.get(data[i][j])\n",
    "            except KeyError:\n",
    "                vector = glove_vectors.get(\"<unk>\")\n",
    "                X[i][j] = np.array(vector)\n",
    "            \n",
    "            if vector is not None:\n",
    "                X[i][j] = np.array(vector)\n",
    "                \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec72ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data):\n",
    "    data = to_lower(data)\n",
    "    data = remove_stopwords(data)\n",
    "    data = remove_tags(data)\n",
    "    data = transform(data)\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(data['headlines'])):\n",
    "        X.append(data['headlines'][i])\n",
    "    \n",
    "    Y = np.array(list(data['sentiment']))\n",
    "    Y = to_categorical(Y)\n",
    "\n",
    "    X = tokenize(X)\n",
    "    X = embed(X)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0481eb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-43e68ddebfdf>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['headlines'] = data['headlines'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
      "<ipython-input-5-83bb5a1a6273>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment'][i] = 2\n",
      "<ipython-input-5-83bb5a1a6273>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment'][i] = 0\n",
      "<ipython-input-5-83bb5a1a6273>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment'][i] = 1\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('sentiment/test.csv').set_axis(['headlines', 'sentiment'], axis=1, inplace=False)\n",
    "X_test, Y_test = prepare(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5791aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.42151999, -0.49518999,  0.09943   , ..., -0.36506   ,\n",
       "         -0.098772  ,  0.60898   ],\n",
       "        [ 0.61084998, -0.52956003, -0.59061998, ..., -0.91993999,\n",
       "          0.39991   ,  0.083406  ],\n",
       "        [-0.27063999,  0.0051896 ,  0.1497    , ..., -0.23097999,\n",
       "          0.54587001,  0.49992001],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.024221  , -0.034855  ,  0.35710001, ..., -0.087568  ,\n",
       "          0.25961   ,  0.050783  ],\n",
       "        [ 0.36204001,  0.43627   ,  0.10537   , ...,  0.19543   ,\n",
       "          0.37797001,  0.40605   ],\n",
       "        [ 0.11945   ,  0.41922   , -0.04461   , ...,  0.17206   ,\n",
       "          0.17687   , -0.44743001],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.17997999, -0.022362  ,  0.28167999, ..., -0.81501001,\n",
       "          0.46667999, -0.40369001],\n",
       "        [ 0.13168   ,  0.31439   ,  0.58740002, ...,  0.026362  ,\n",
       "          0.31636   ,  0.42177999],\n",
       "        [-0.37272   ,  0.24501   ,  0.059596  , ..., -0.53742999,\n",
       "          0.28139001, -0.55864   ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.10236   ,  0.24177   , -0.49421999, ...,  0.36537001,\n",
       "         -0.75692999,  0.36105001],\n",
       "        [-0.048494  ,  0.22747   ,  0.87540001, ...,  0.072322  ,\n",
       "          0.65995002, -0.25547001],\n",
       "        [ 0.51435   ,  0.059716  ,  0.70214999, ..., -0.049566  ,\n",
       "          0.68102998, -0.51854002],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.90860999,  0.90711999, -0.091478  , ..., -0.37720001,\n",
       "         -0.27770999,  0.42385   ],\n",
       "        [ 0.10701   ,  0.89111   , -0.42265999, ...,  0.24273001,\n",
       "          0.21945   ,  0.81383997],\n",
       "        [-0.086607  ,  0.66421002,  0.25163001, ..., -0.42660001,\n",
       "         -0.23091   ,  0.95933998],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.19351   ,  0.68441999,  0.31433001, ..., -0.65451002,\n",
       "          0.50874001, -0.039126  ],\n",
       "        [ 0.56448001,  0.25171   , -0.65268999, ...,  0.22484   ,\n",
       "         -0.37145001,  0.2244    ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd6920b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc3ec13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('BiLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44925cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 6ms/step - loss: 0.8584 - accuracy: 0.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8584498763084412, 0.63163161277771]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4488b52",
   "metadata": {},
   "source": [
    "## Model Inference (Single Headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8100e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(headline):\n",
    "    headline = headline.lower()\n",
    "    headline = ' '.join([word for word in headline.split() if word not in stopwords])\n",
    "    headline = re.sub(r'[^\\w\\s]','',headline)\n",
    "    headline_tokens = nltk.word_tokenize(headline)\n",
    "\n",
    "    glove_vectors = load_glove()\n",
    "    dim = glove_vectors[\"random\"].shape[0]\n",
    "    \n",
    "    X = np.zeros((64, 100))\n",
    "    \n",
    "\n",
    "    for i in range(len(headline_tokens)):\n",
    "        try:\n",
    "            vector = glove_vectors.get(headline_tokens[i])\n",
    "        \n",
    "        except KeyError:\n",
    "            vector = glove_vectors.get(\"<unk>\")\n",
    "            X[i] = np.array(vector)\n",
    "        \n",
    "        if vector is not None:\n",
    "            X[i] = np.array(vector)\n",
    "                \n",
    "    X = np.reshape(X, (-1,64,100))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccf032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(headline):\n",
    "    \n",
    "    X = preprocess(headline)\n",
    "    model = tf.keras.models.load_model('BiLSTM')\n",
    "    pred = model.predict(X)\n",
    "    \n",
    "    if np.argmax(pred) == 0:\n",
    "        result = \"Neutral\"\n",
    "        \n",
    "    elif np.argmax(pred) == 1:\n",
    "        result = \"Positive\"\n",
    "        \n",
    "    else:\n",
    "        result = \"Negative\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "634f475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "headline = \"Government allocates RM10m to revive retail sector, says PM\"\n",
    "sentiment = get_prediction(headline)\n",
    "\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6578a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
